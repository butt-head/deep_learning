{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nWgQSUFlamqG"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "import re\n",
        "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from cifar10 import CIFAR10\n",
        "\n",
        "from cifar_competition_model_class import Model as Model_CNN\n",
        "\n",
        "\n",
        "# TODO: Define reasonable defaults and optionally more parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--batch_size\", default=256, type=int, help=\"Batch size.\")\n",
        "parser.add_argument(\"--epochs\", default=10, type=int, help=\"Number of epochs.\")\n",
        "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n",
        "parser.add_argument(\"--threads\", default=4, type=int, help=\"Maximum number of threads to use.\")\n",
        "parser.add_argument(\"--cnn\", default='CB-32-3-2-same,M-2-1,CB-64-3-2-same,M-2-1,R-[CB-64-3-1-same,CB-64-3-1-same],CB-126-3-2-same,M-2-1,F,H-2048,H-2048', type=str, help=\"CNN architecture.\")\n",
        "parser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Initial learning rate.\")\n",
        "parser.add_argument(\"--learning_rate_final\", default=0.001, type=float, help=\"Final learning rate.\")\n",
        "parser.add_argument(\"--momentum\", default=0.9, type=float, help=\"Momentum.\")\n",
        "parser.add_argument(\"--optimizer\", default=\"SGD\", type=str, help=\"Optimizer to use.\")\n",
        "parser.add_argument(\"--decay_steps\", default=100, type=int, help=\"decay_steps.\")\n",
        "parser.add_argument(\"--vgg_rep\", default=100, type=int, help=\"number of repetitions of conv/maxpool in the style of vgg\")\n",
        "\n",
        "def main(args: argparse.Namespace): # -> None:\n",
        "    # Fix random seeds and threads\n",
        "    tf.keras.utils.set_random_seed(args.seed)\n",
        "    tf.config.threading.set_inter_op_parallelism_threads(args.threads)\n",
        "    tf.config.threading.set_intra_op_parallelism_threads(args.threads)\n",
        "\n",
        "    # Create logdir name\n",
        "    # args.logdir = os.path.join(\"logs\", \"{}-{}-{}\".format(\n",
        "    #     os.path.basename(globals().get(\"__file__\", \"notebook\")),\n",
        "    #     datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"),\n",
        "    #     \",\".join((\"{}={}\".format(re.sub(\"(.)[^_]*_?\", r\"\\1\", k), v) for k, v in sorted(vars(args).items())))\n",
        "    # ))\n",
        "\n",
        "    args.logdir = os.path.join(\"logs\", \"{}-{}\".format(\n",
        "        os.path.basename(globals().get(\"__file__\", \"notebook\")),\n",
        "        datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"),\n",
        "        # \",\".join((\"{}={}\".format(re.sub(\"(.)[^_]*_?\", r\"\\1\", k), v) for k, v in sorted(vars(args).items())))\n",
        "    ))\n",
        "\n",
        "    pars = \"{}\".format(\n",
        "        \",\".join((\"{}={}\".format(re.sub(\"(.)[^_]*_?\", r\"\\1\", k), v) for k, v in sorted(vars(args).items())))\n",
        "    )\n",
        "\n",
        "    # Load data\n",
        "    cifar = CIFAR10()\n",
        "\n",
        "    # TODO: Create the model and train it\n",
        "    model = Model_CNN(args)\n",
        "\n",
        "\n",
        "    train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=20,  zoom_range=0.2, width_shift_range=0.1, horizontal_flip=True\n",
        "                            )\n",
        "    # tb_callback = tf.keras.callbacks.TensorBoard(args.logdir[:-57], update_freq=100, profile_batch=0)\n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(args.logdir[:-56], update_freq=100, profile_batch=0)\n",
        "    tb_callback._close_writers = lambda: None # A hack allowing to keep the writers open.\n",
        "    model.fit(\n",
        "        train_generator.flow(cifar.train.data[\"images\"], \n",
        "                            y=cifar.train.data[\"labels\"], \n",
        "                            batch_size=args.batch_size, \n",
        "                            seed=args.seed, \n",
        "                            shuffle=True),\n",
        "        shuffle=False, \n",
        "        batch_size=args.batch_size, epochs=args.epochs,\n",
        "        validation_data=(cifar.dev.data[\"images\"], cifar.dev.data[\"labels\"]),\n",
        "        callbacks=[tb_callback]\n",
        "    )\n",
        "\n",
        "    # np.savetxt(args.logdir+os.sep+'pars.txt', pars)\n",
        "\n",
        "    # Generate test set annotations, but in `args.logdir` to allow parallel execution.\n",
        "    os.makedirs(args.logdir, exist_ok=True)\n",
        "    with open(os.path.join(args.logdir, \"cifar_competition_test.txt\"), \"w\", encoding=\"utf-8\") as predictions_file:\n",
        "        for probs in model.predict(cifar.test.data[\"images\"], batch_size=args.batch_size):\n",
        "            print(np.argmax(probs), file=predictions_file)\n",
        "    \n",
        "    with open(os.path.join(args.logdir, \"pars.txt\"), \"w\", encoding=\"utf-8\") as pars_file:\n",
        "        print(pars, file=pars_file)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define reasonable defaults and optionally more parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--batch_size\", default=256, type=int, help=\"Batch size.\")\n",
        "parser.add_argument(\"--epochs\", default=150, type=int, help=\"Number of epochs.\")\n",
        "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n",
        "parser.add_argument(\"--threads\", default=4, type=int, help=\"Maximum number of threads to use.\")\n",
        "parser.add_argument(\"--cnn\", default='CB-64-3-2-same,M-2-1,CB-128-3-2-same,M-2-1,R-[CB-64-3-1-same,CB-128-3-1-same],CB-256-3-2-same,M-2-1,F,H-4096,H-4096', type=str, help=\"CNN architecture.\")\n",
        "parser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Initial learning rate.\")\n",
        "parser.add_argument(\"--learning_rate_final\", default=0.001, type=float, help=\"Final learning rate.\")\n",
        "parser.add_argument(\"--momentum\", default=0.9, type=float, help=\"Momentum.\")\n",
        "parser.add_argument(\"--optimizer\", default=\"SGD\", type=str, help=\"Optimizer to use.\")\n",
        "parser.add_argument(\"--decay_steps\", default=100, type=int, help=\"decay_steps.\")\n",
        "args = parser.parse_args([] if \"__file__\" not in globals() else None)\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as6FP8U6ayCe",
        "outputId": "53d5beaf-255d-430b-e4d2-cb15271e2850"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=256, cnn='CB-64-3-2-same,M-2-1,CB-128-3-2-same,M-2-1,R-[CB-64-3-1-same,CB-128-3-1-same],CB-256-3-2-same,M-2-1,F,H-4096,H-4096', decay_steps=100, epochs=150, learning_rate=0.01, learning_rate_final=0.001, momentum=0.9, optimizer='SGD', seed=42, threads=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# time.sleep(900)"
      ],
      "metadata": {
        "id": "og1NCuC6a8BC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl56MlT9bC1X",
        "outputId": "62fb470c-65d5-4895-eaf6-4ca8695904dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "176/176 [==============================] - 29s 103ms/step - loss: 1.5832 - accuracy: 0.4364 - val_loss: 3.2348 - val_accuracy: 0.1052\n",
            "Epoch 2/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 1.3197 - accuracy: 0.5263 - val_loss: 2.8829 - val_accuracy: 0.2132\n",
            "Epoch 3/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 1.2475 - accuracy: 0.5536 - val_loss: 1.6779 - val_accuracy: 0.4038\n",
            "Epoch 4/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 1.1823 - accuracy: 0.5790 - val_loss: 1.1754 - val_accuracy: 0.5762\n",
            "Epoch 5/150\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 1.1332 - accuracy: 0.5978 - val_loss: 1.1303 - val_accuracy: 0.5960\n",
            "Epoch 6/150\n",
            "176/176 [==============================] - 18s 99ms/step - loss: 1.0931 - accuracy: 0.6128 - val_loss: 1.0647 - val_accuracy: 0.6176\n",
            "Epoch 7/150\n",
            "176/176 [==============================] - 18s 103ms/step - loss: 1.0507 - accuracy: 0.6270 - val_loss: 1.2638 - val_accuracy: 0.5618\n",
            "Epoch 8/150\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 1.0161 - accuracy: 0.6423 - val_loss: 1.1386 - val_accuracy: 0.6044\n",
            "Epoch 9/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.9914 - accuracy: 0.6484 - val_loss: 1.2779 - val_accuracy: 0.5730\n",
            "Epoch 10/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.9694 - accuracy: 0.6591 - val_loss: 1.1715 - val_accuracy: 0.5880\n",
            "Epoch 11/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.9370 - accuracy: 0.6721 - val_loss: 0.9050 - val_accuracy: 0.6804\n",
            "Epoch 12/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.9139 - accuracy: 0.6782 - val_loss: 0.9906 - val_accuracy: 0.6546\n",
            "Epoch 13/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.8899 - accuracy: 0.6869 - val_loss: 1.0575 - val_accuracy: 0.6358\n",
            "Epoch 14/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.8720 - accuracy: 0.6918 - val_loss: 1.0843 - val_accuracy: 0.6352\n",
            "Epoch 15/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.8559 - accuracy: 0.6993 - val_loss: 0.9340 - val_accuracy: 0.6736\n",
            "Epoch 16/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.8429 - accuracy: 0.7044 - val_loss: 1.0720 - val_accuracy: 0.6354\n",
            "Epoch 17/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.8204 - accuracy: 0.7122 - val_loss: 0.9514 - val_accuracy: 0.6652\n",
            "Epoch 18/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.8048 - accuracy: 0.7180 - val_loss: 0.9640 - val_accuracy: 0.6624\n",
            "Epoch 19/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.7912 - accuracy: 0.7233 - val_loss: 0.9956 - val_accuracy: 0.6588\n",
            "Epoch 20/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.7797 - accuracy: 0.7274 - val_loss: 1.3594 - val_accuracy: 0.5734\n",
            "Epoch 21/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.7661 - accuracy: 0.7323 - val_loss: 0.8413 - val_accuracy: 0.7086\n",
            "Epoch 22/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.7567 - accuracy: 0.7367 - val_loss: 1.0515 - val_accuracy: 0.6626\n",
            "Epoch 23/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.7475 - accuracy: 0.7377 - val_loss: 1.0751 - val_accuracy: 0.6456\n",
            "Epoch 24/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.7355 - accuracy: 0.7438 - val_loss: 0.8027 - val_accuracy: 0.7170\n",
            "Epoch 25/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.7256 - accuracy: 0.7465 - val_loss: 0.7461 - val_accuracy: 0.7366\n",
            "Epoch 26/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.7167 - accuracy: 0.7477 - val_loss: 0.7309 - val_accuracy: 0.7432\n",
            "Epoch 27/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.7048 - accuracy: 0.7536 - val_loss: 0.7241 - val_accuracy: 0.7448\n",
            "Epoch 28/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6913 - accuracy: 0.7575 - val_loss: 0.8372 - val_accuracy: 0.7088\n",
            "Epoch 29/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.6838 - accuracy: 0.7602 - val_loss: 0.7077 - val_accuracy: 0.7526\n",
            "Epoch 30/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6754 - accuracy: 0.7642 - val_loss: 0.7212 - val_accuracy: 0.7526\n",
            "Epoch 31/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.6702 - accuracy: 0.7677 - val_loss: 0.7300 - val_accuracy: 0.7442\n",
            "Epoch 32/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.6617 - accuracy: 0.7680 - val_loss: 1.0392 - val_accuracy: 0.6652\n",
            "Epoch 33/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6518 - accuracy: 0.7719 - val_loss: 0.7920 - val_accuracy: 0.7264\n",
            "Epoch 34/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6432 - accuracy: 0.7759 - val_loss: 0.8226 - val_accuracy: 0.7210\n",
            "Epoch 35/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6380 - accuracy: 0.7780 - val_loss: 0.8193 - val_accuracy: 0.7200\n",
            "Epoch 36/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6263 - accuracy: 0.7823 - val_loss: 0.7088 - val_accuracy: 0.7464\n",
            "Epoch 37/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6159 - accuracy: 0.7846 - val_loss: 0.6440 - val_accuracy: 0.7714\n",
            "Epoch 38/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.6117 - accuracy: 0.7857 - val_loss: 0.8717 - val_accuracy: 0.7130\n",
            "Epoch 39/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.6060 - accuracy: 0.7884 - val_loss: 0.7384 - val_accuracy: 0.7444\n",
            "Epoch 40/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.5980 - accuracy: 0.7911 - val_loss: 0.6692 - val_accuracy: 0.7636\n",
            "Epoch 41/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5844 - accuracy: 0.7966 - val_loss: 0.7462 - val_accuracy: 0.7478\n",
            "Epoch 42/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5882 - accuracy: 0.7936 - val_loss: 0.9493 - val_accuracy: 0.6948\n",
            "Epoch 43/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.5816 - accuracy: 0.7970 - val_loss: 0.7104 - val_accuracy: 0.7592\n",
            "Epoch 44/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5713 - accuracy: 0.8004 - val_loss: 0.7975 - val_accuracy: 0.7380\n",
            "Epoch 45/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5654 - accuracy: 0.7999 - val_loss: 0.6868 - val_accuracy: 0.7636\n",
            "Epoch 46/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.5625 - accuracy: 0.8058 - val_loss: 0.7680 - val_accuracy: 0.7362\n",
            "Epoch 47/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5555 - accuracy: 0.8056 - val_loss: 0.7478 - val_accuracy: 0.7522\n",
            "Epoch 48/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5534 - accuracy: 0.8054 - val_loss: 0.9519 - val_accuracy: 0.6960\n",
            "Epoch 49/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.5453 - accuracy: 0.8085 - val_loss: 0.7891 - val_accuracy: 0.7290\n",
            "Epoch 50/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.5436 - accuracy: 0.8107 - val_loss: 0.6668 - val_accuracy: 0.7706\n",
            "Epoch 51/150\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 0.5393 - accuracy: 0.8125 - val_loss: 0.7101 - val_accuracy: 0.7624\n",
            "Epoch 52/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5276 - accuracy: 0.8173 - val_loss: 0.6703 - val_accuracy: 0.7692\n",
            "Epoch 53/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.5176 - accuracy: 0.8185 - val_loss: 0.8064 - val_accuracy: 0.7282\n",
            "Epoch 54/150\n",
            "176/176 [==============================] - 18s 102ms/step - loss: 0.5219 - accuracy: 0.8182 - val_loss: 0.9593 - val_accuracy: 0.6936\n",
            "Epoch 55/150\n",
            "176/176 [==============================] - 18s 103ms/step - loss: 0.5102 - accuracy: 0.8208 - val_loss: 0.6277 - val_accuracy: 0.7836\n",
            "Epoch 56/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5049 - accuracy: 0.8240 - val_loss: 0.6817 - val_accuracy: 0.7690\n",
            "Epoch 57/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.5091 - accuracy: 0.8217 - val_loss: 0.6184 - val_accuracy: 0.7854\n",
            "Epoch 58/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4990 - accuracy: 0.8259 - val_loss: 0.6864 - val_accuracy: 0.7680\n",
            "Epoch 59/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4928 - accuracy: 0.8266 - val_loss: 0.6912 - val_accuracy: 0.7610\n",
            "Epoch 60/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4842 - accuracy: 0.8303 - val_loss: 0.9649 - val_accuracy: 0.7070\n",
            "Epoch 61/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4866 - accuracy: 0.8297 - val_loss: 0.6471 - val_accuracy: 0.7804\n",
            "Epoch 62/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4803 - accuracy: 0.8293 - val_loss: 0.6203 - val_accuracy: 0.7864\n",
            "Epoch 63/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4713 - accuracy: 0.8354 - val_loss: 0.6232 - val_accuracy: 0.7894\n",
            "Epoch 64/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.4678 - accuracy: 0.8368 - val_loss: 0.7197 - val_accuracy: 0.7576\n",
            "Epoch 65/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4658 - accuracy: 0.8380 - val_loss: 0.6017 - val_accuracy: 0.7880\n",
            "Epoch 66/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4630 - accuracy: 0.8373 - val_loss: 0.5931 - val_accuracy: 0.7942\n",
            "Epoch 67/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.4595 - accuracy: 0.8378 - val_loss: 0.5760 - val_accuracy: 0.8014\n",
            "Epoch 68/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4570 - accuracy: 0.8389 - val_loss: 0.8020 - val_accuracy: 0.7402\n",
            "Epoch 69/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4474 - accuracy: 0.8444 - val_loss: 0.6313 - val_accuracy: 0.7824\n",
            "Epoch 70/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4473 - accuracy: 0.8448 - val_loss: 0.6274 - val_accuracy: 0.7882\n",
            "Epoch 71/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4422 - accuracy: 0.8444 - val_loss: 0.7301 - val_accuracy: 0.7600\n",
            "Epoch 72/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4437 - accuracy: 0.8446 - val_loss: 0.8492 - val_accuracy: 0.7222\n",
            "Epoch 73/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.4326 - accuracy: 0.8485 - val_loss: 0.7380 - val_accuracy: 0.7692\n",
            "Epoch 74/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4302 - accuracy: 0.8493 - val_loss: 0.5901 - val_accuracy: 0.7930\n",
            "Epoch 75/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4244 - accuracy: 0.8509 - val_loss: 0.6132 - val_accuracy: 0.7910\n",
            "Epoch 76/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4255 - accuracy: 0.8501 - val_loss: 0.6996 - val_accuracy: 0.7642\n",
            "Epoch 77/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4188 - accuracy: 0.8518 - val_loss: 0.7563 - val_accuracy: 0.7586\n",
            "Epoch 78/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4209 - accuracy: 0.8524 - val_loss: 0.7483 - val_accuracy: 0.7666\n",
            "Epoch 79/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4169 - accuracy: 0.8545 - val_loss: 0.5836 - val_accuracy: 0.7982\n",
            "Epoch 80/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4072 - accuracy: 0.8580 - val_loss: 0.7038 - val_accuracy: 0.7670\n",
            "Epoch 81/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4068 - accuracy: 0.8574 - val_loss: 0.6447 - val_accuracy: 0.7840\n",
            "Epoch 82/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.4065 - accuracy: 0.8568 - val_loss: 0.6285 - val_accuracy: 0.7852\n",
            "Epoch 83/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.4011 - accuracy: 0.8578 - val_loss: 0.6002 - val_accuracy: 0.7974\n",
            "Epoch 84/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3954 - accuracy: 0.8608 - val_loss: 0.6644 - val_accuracy: 0.7814\n",
            "Epoch 85/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3922 - accuracy: 0.8634 - val_loss: 0.7019 - val_accuracy: 0.7610\n",
            "Epoch 86/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3866 - accuracy: 0.8645 - val_loss: 0.6898 - val_accuracy: 0.7738\n",
            "Epoch 87/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3851 - accuracy: 0.8669 - val_loss: 0.6128 - val_accuracy: 0.7962\n",
            "Epoch 88/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3858 - accuracy: 0.8653 - val_loss: 0.6529 - val_accuracy: 0.7894\n",
            "Epoch 89/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3792 - accuracy: 0.8661 - val_loss: 0.8688 - val_accuracy: 0.7508\n",
            "Epoch 90/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3811 - accuracy: 0.8651 - val_loss: 0.6130 - val_accuracy: 0.7928\n",
            "Epoch 91/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3695 - accuracy: 0.8711 - val_loss: 0.6376 - val_accuracy: 0.7948\n",
            "Epoch 92/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.3665 - accuracy: 0.8707 - val_loss: 0.6051 - val_accuracy: 0.7950\n",
            "Epoch 93/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3673 - accuracy: 0.8714 - val_loss: 0.6853 - val_accuracy: 0.7740\n",
            "Epoch 94/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3617 - accuracy: 0.8728 - val_loss: 0.6632 - val_accuracy: 0.7878\n",
            "Epoch 95/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3555 - accuracy: 0.8761 - val_loss: 0.6146 - val_accuracy: 0.7910\n",
            "Epoch 96/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3546 - accuracy: 0.8762 - val_loss: 0.6217 - val_accuracy: 0.8010\n",
            "Epoch 97/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3524 - accuracy: 0.8762 - val_loss: 0.6736 - val_accuracy: 0.7772\n",
            "Epoch 98/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3453 - accuracy: 0.8803 - val_loss: 0.5992 - val_accuracy: 0.7936\n",
            "Epoch 99/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3471 - accuracy: 0.8780 - val_loss: 0.6559 - val_accuracy: 0.7870\n",
            "Epoch 100/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3457 - accuracy: 0.8790 - val_loss: 0.9329 - val_accuracy: 0.7416\n",
            "Epoch 101/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.3392 - accuracy: 0.8800 - val_loss: 0.6186 - val_accuracy: 0.7956\n",
            "Epoch 102/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3380 - accuracy: 0.8820 - val_loss: 0.8092 - val_accuracy: 0.7554\n",
            "Epoch 103/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3360 - accuracy: 0.8815 - val_loss: 0.6963 - val_accuracy: 0.7806\n",
            "Epoch 104/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3314 - accuracy: 0.8825 - val_loss: 0.6252 - val_accuracy: 0.7948\n",
            "Epoch 105/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3324 - accuracy: 0.8844 - val_loss: 0.7162 - val_accuracy: 0.7786\n",
            "Epoch 106/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3280 - accuracy: 0.8841 - val_loss: 1.0552 - val_accuracy: 0.7206\n",
            "Epoch 107/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3268 - accuracy: 0.8869 - val_loss: 0.7873 - val_accuracy: 0.7642\n",
            "Epoch 108/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3185 - accuracy: 0.8874 - val_loss: 0.6566 - val_accuracy: 0.7878\n",
            "Epoch 109/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.3223 - accuracy: 0.8874 - val_loss: 0.5994 - val_accuracy: 0.8090\n",
            "Epoch 110/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.3139 - accuracy: 0.8888 - val_loss: 0.6723 - val_accuracy: 0.7932\n",
            "Epoch 111/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.3119 - accuracy: 0.8906 - val_loss: 0.6315 - val_accuracy: 0.7964\n",
            "Epoch 112/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.3166 - accuracy: 0.8890 - val_loss: 0.6228 - val_accuracy: 0.8004\n",
            "Epoch 113/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.3130 - accuracy: 0.8890 - val_loss: 0.7287 - val_accuracy: 0.7786\n",
            "Epoch 114/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.3108 - accuracy: 0.8901 - val_loss: 0.6583 - val_accuracy: 0.7950\n",
            "Epoch 115/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.2999 - accuracy: 0.8958 - val_loss: 0.6207 - val_accuracy: 0.8032\n",
            "Epoch 116/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2996 - accuracy: 0.8945 - val_loss: 0.6812 - val_accuracy: 0.7826\n",
            "Epoch 117/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2926 - accuracy: 0.8959 - val_loss: 0.7025 - val_accuracy: 0.7832\n",
            "Epoch 118/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.2955 - accuracy: 0.8966 - val_loss: 0.9218 - val_accuracy: 0.7498\n",
            "Epoch 119/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2928 - accuracy: 0.8977 - val_loss: 0.5757 - val_accuracy: 0.8110\n",
            "Epoch 120/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2870 - accuracy: 0.8987 - val_loss: 0.6722 - val_accuracy: 0.7938\n",
            "Epoch 121/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.2871 - accuracy: 0.9003 - val_loss: 0.6238 - val_accuracy: 0.8056\n",
            "Epoch 122/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2797 - accuracy: 0.9020 - val_loss: 0.6239 - val_accuracy: 0.8000\n",
            "Epoch 123/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.2835 - accuracy: 0.9001 - val_loss: 0.6423 - val_accuracy: 0.7972\n",
            "Epoch 124/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2822 - accuracy: 0.9006 - val_loss: 0.6993 - val_accuracy: 0.7866\n",
            "Epoch 125/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2742 - accuracy: 0.9044 - val_loss: 0.7600 - val_accuracy: 0.7746\n",
            "Epoch 126/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2770 - accuracy: 0.9024 - val_loss: 0.5811 - val_accuracy: 0.8132\n",
            "Epoch 127/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2734 - accuracy: 0.9041 - val_loss: 0.5880 - val_accuracy: 0.8116\n",
            "Epoch 128/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2695 - accuracy: 0.9050 - val_loss: 0.7148 - val_accuracy: 0.7842\n",
            "Epoch 129/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2696 - accuracy: 0.9057 - val_loss: 0.6473 - val_accuracy: 0.8046\n",
            "Epoch 130/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2694 - accuracy: 0.9054 - val_loss: 0.6342 - val_accuracy: 0.7998\n",
            "Epoch 131/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2678 - accuracy: 0.9052 - val_loss: 0.6587 - val_accuracy: 0.7988\n",
            "Epoch 132/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2649 - accuracy: 0.9067 - val_loss: 0.6606 - val_accuracy: 0.7990\n",
            "Epoch 133/150\n",
            "176/176 [==============================] - 18s 99ms/step - loss: 0.2618 - accuracy: 0.9089 - val_loss: 0.6443 - val_accuracy: 0.8064\n",
            "Epoch 134/150\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 0.2556 - accuracy: 0.9118 - val_loss: 0.6599 - val_accuracy: 0.7978\n",
            "Epoch 135/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.2581 - accuracy: 0.9091 - val_loss: 0.6974 - val_accuracy: 0.7878\n",
            "Epoch 136/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2549 - accuracy: 0.9113 - val_loss: 0.6893 - val_accuracy: 0.7882\n",
            "Epoch 137/150\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 0.2541 - accuracy: 0.9105 - val_loss: 0.6234 - val_accuracy: 0.8022\n",
            "Epoch 138/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2492 - accuracy: 0.9130 - val_loss: 0.6784 - val_accuracy: 0.8012\n",
            "Epoch 139/150\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 0.2487 - accuracy: 0.9135 - val_loss: 0.8394 - val_accuracy: 0.7656\n",
            "Epoch 140/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2466 - accuracy: 0.9129 - val_loss: 0.6544 - val_accuracy: 0.8028\n",
            "Epoch 141/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2408 - accuracy: 0.9148 - val_loss: 0.6334 - val_accuracy: 0.8064\n",
            "Epoch 142/150\n",
            "176/176 [==============================] - 18s 99ms/step - loss: 0.2432 - accuracy: 0.9146 - val_loss: 0.5909 - val_accuracy: 0.8116\n",
            "Epoch 143/150\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 0.2434 - accuracy: 0.9151 - val_loss: 0.6156 - val_accuracy: 0.8132\n",
            "Epoch 144/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.2360 - accuracy: 0.9171 - val_loss: 0.6509 - val_accuracy: 0.8002\n",
            "Epoch 145/150\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.2369 - accuracy: 0.9174 - val_loss: 0.6622 - val_accuracy: 0.7914\n",
            "Epoch 146/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.2323 - accuracy: 0.9193 - val_loss: 0.5879 - val_accuracy: 0.8196\n",
            "Epoch 147/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.2302 - accuracy: 0.9188 - val_loss: 0.8583 - val_accuracy: 0.7638\n",
            "Epoch 148/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.2278 - accuracy: 0.9198 - val_loss: 0.5940 - val_accuracy: 0.8176\n",
            "Epoch 149/150\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.2275 - accuracy: 0.9197 - val_loss: 0.6752 - val_accuracy: 0.8056\n",
            "Epoch 150/150\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 0.2270 - accuracy: 0.9208 - val_loss: 0.6227 - val_accuracy: 0.8110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "VRzXQEuLbOos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define reasonable defaults and optionally more parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--batch_size\", default=256, type=int, help=\"Batch size.\")\n",
        "parser.add_argument(\"--epochs\", default=250, type=int, help=\"Number of epochs.\")\n",
        "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n",
        "parser.add_argument(\"--threads\", default=4, type=int, help=\"Maximum number of threads to use.\")\n",
        "parser.add_argument(\"--cnn\", default='CB-64-3-2-same,M-2-1,CB-128-3-2-same,M-2-1,R-[CB-64-3-1-same,CB-128-3-1-same],CB-256-3-2-same,M-2-1,F,H-4096,H-4096', type=str, help=\"CNN architecture.\")\n",
        "parser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Initial learning rate.\")\n",
        "parser.add_argument(\"--learning_rate_final\", default=0.001, type=float, help=\"Final learning rate.\")\n",
        "parser.add_argument(\"--momentum\", default=0.9, type=float, help=\"Momentum.\")\n",
        "parser.add_argument(\"--optimizer\", default=\"SGD\", type=str, help=\"Optimizer to use.\")\n",
        "parser.add_argument(\"--decay_steps\", default=100, type=int, help=\"decay_steps.\")\n",
        "args = parser.parse_args([] if \"__file__\" not in globals() else None)\n",
        "print(args)"
      ],
      "metadata": {
        "id": "vrcHgmawjWDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(args)"
      ],
      "metadata": {
        "id": "dD0OnydejLGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(3600)"
      ],
      "metadata": {
        "id": "buxoVKb5gKmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}